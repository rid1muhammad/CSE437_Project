{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cardiovascular Disease Risk Analysis\n",
                "\n",
                "## 1. Introduction\n",
                "This notebook analyzes the risk factors associated with Cardiovascular Disease (CVD) using machine learning techniques. We interpret the `cardio_train.csv` dataset to train various classification models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "import sys\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.svm import LinearSVC\n",
                "from sklearn.tree import DecisionTreeClassifier, export_text\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
                "from sklearn.neighbors import KNeighborsClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "\n",
                "# Ensure plots display in the notebook\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading and Preprocessing\n",
                "We load the data, remove duplicates, and perform necessary cleaning steps like handling outliers in blood pressure and height/weight data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_and_preprocess(filepath):\n",
                "    print(f\"Loading data from {filepath}...\")\n",
                "    df = pd.read_csv(filepath, sep=';')\n",
                "    \n",
                "    # --- Show Shapes BEFORE Preprocessing ---\n",
                "    initial_shape = df.shape\n",
                "    print(f\"\\n--- User Requested Information ---\")\n",
                "    print(f\"Data Shape BEFORE Preprocessing: {initial_shape}\")\n",
                "    print(f\"----------------------------------\\n\")\n",
                "\n",
                "    if 'id' in df.columns:\n",
                "        df.drop('id', axis=1, inplace=True)\n",
                "\n",
                "    df['age_years'] = (df['age'] / 365.25).round(1)\n",
                "    \n",
                "    dupes = df.duplicated().sum()\n",
                "    if dupes > 0:\n",
                "        print(f\"Removing {dupes} duplicate rows...\")\n",
                "        df.drop_duplicates(inplace=True)\n",
                "\n",
                "    mask = (df['ap_hi'] >= 60) & (df['ap_hi'] <= 240) & \\\n",
                "           (df['ap_lo'] >= 30) & (df['ap_lo'] <= 160) & \\\n",
                "           (df['ap_hi'] > df['ap_lo'])\n",
                "    \n",
                "    df_clean = df[mask].copy()\n",
                "    print(f\"Rows after blood pressure cleaning: {df_clean.shape[0]} (removed {df.shape[0] - df_clean.shape[0]})\")\n",
                "    \n",
                "    df_clean = df_clean[(df_clean['height'] > 100) & (df_clean['weight'] > 30)]\n",
                "    \n",
                "    # --- Show Shapes AFTER Preprocessing ---\n",
                "    final_shape = df_clean.shape\n",
                "    print(f\"\\n--- User Requested Information ---\")\n",
                "    print(f\"Final Data Shape AFTER Preprocessing: {final_shape}\")\n",
                "    print(f\"----------------------------------\\n\")\n",
                "\n",
                "    return df_clean\n",
                "\n",
                "# Execution\n",
                "data_path = \"f:/venv/cvd_analysis/cardio_train.csv\"\n",
                "df = load_and_preprocess(data_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Exploratory Data Analysis\n",
                "Here we visualize some basic distributions and analyze the effect of smoking."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def optimize_visuals(df):\n",
                "    plt.figure(figsize=(6, 5))\n",
                "    sns.countplot(x='smoke', hue='cardio', data=df)\n",
                "    plt.title('CVD Cases by Smoking Status')\n",
                "    plt.xlabel('Smoking Status (0=No, 1=Yes)')\n",
                "    plt.ylabel('Count')\n",
                "    plt.legend(title='CVD', labels=['No', 'Yes'])\n",
                "    plt.show()\n",
                "\n",
                "def analyze_smoking_effect(df):\n",
                "    print(\"\\n--- Analysis: Effect of Smoking on CVD ---\")\n",
                "    \n",
                "    prevalence = df.groupby('smoke')['cardio'].mean()\n",
                "    print(\"\\nCVD Prevalence:\")\n",
                "    print(f\"Non-Smokers (0): {prevalence[0]*100:.2f}%\")\n",
                "    print(f\"Smokers (1):     {prevalence[1]*100:.2f}%\")\n",
                "    \n",
                "    ct = pd.crosstab(df['smoke'], df['cardio'])\n",
                "    odds_smoker = ct.iloc[1, 1] / ct.iloc[1, 0]\n",
                "    odds_nonsmoker = ct.iloc[0, 1] / ct.iloc[0, 0]\n",
                "    or_val = odds_smoker / odds_nonsmoker\n",
                "    \n",
                "    print(\"\\nUnadjusted Odds Ratio (Smoker vs Non-Smoker):\")\n",
                "    print(f\"OR: {or_val:.4f}\")\n",
                "    if or_val > 1:\n",
                "        print(\"Interpretation: Smokers have higher odds of CVD compared to non-smokers (in this unadjusted view).\")\n",
                "    else:\n",
                "        print(\"Interpretation: Smokers have lower/equal odds of CVD compared to non-smokers (unexpected, likely due to age confounding).\")\n",
                "\n",
                "optimize_visuals(df)\n",
                "analyze_smoking_effect(df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Training and Evaluation\n",
                "We train multiple models ranging from Logistic Regression to Ensemble methods like Gradient Boosting and Voting Classifiers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_and_evaluate(df):\n",
                "    print(\"\\n--- Model Training & Evaluation ---\")\n",
                "    \n",
                "    features = ['age_years', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', \n",
                "                'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
                "    target = 'cardio'\n",
                "    \n",
                "    X = df[features]\n",
                "    y = df[target]\n",
                "    \n",
                "    scaler = StandardScaler()\n",
                "    X_scaled = scaler.fit_transform(X)\n",
                "    \n",
                "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
                "    \n",
                "    # Initialize individual models\n",
                "    lr = LogisticRegression(max_iter=1000)\n",
                "    knn = KNeighborsClassifier(n_neighbors=5)\n",
                "    svm = LinearSVC(random_state=42, dual=False)\n",
                "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "    dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
                "    nb = GaussianNB()\n",
                "    gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
                "    ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
                "    \n",
                "    # Create a Voting Classifier (Ensemble)\n",
                "    voting_clf = VotingClassifier(\n",
                "        estimators=[('lr', lr), ('rf', rf), ('gb', gb)],\n",
                "        voting='hard'\n",
                "    )\n",
                "\n",
                "    models = {\n",
                "        \"Logistic Regression\": lr,\n",
                "        \"K-Nearest Neighbors\": knn,\n",
                "        \"SVM\": svm,\n",
                "        \"Decision Tree\": dt,\n",
                "        \"Naive Bayes\": nb,\n",
                "        \"Random Forest\": rf,\n",
                "        \"Gradient Boosting\": gb,\n",
                "        \"AdaBoost\": ada,\n",
                "        \"Voting Classifier\": voting_clf\n",
                "    }\n",
                "    \n",
                "    model_performance = []\n",
                "\n",
                "    for name, model in models.items():\n",
                "        print(f\"\\nTraining {name}...\")\n",
                "        model.fit(X_train, y_train)\n",
                "        preds = model.predict(X_test)\n",
                "        acc = accuracy_score(y_test, preds)\n",
                "        print(f\"{name} Accuracy: {acc:.4f}\")\n",
                "        # print(classification_report(y_test, preds)) # Optional: Uncomment for full report\n",
                "        \n",
                "        model_performance.append({'Model': name, 'Accuracy': acc})\n",
                "\n",
                "        if name == \"Logistic Regression\":\n",
                "            print(\"Logistic Regression Coefficients (Feature Importance):\")\n",
                "            coeffs = pd.DataFrame({\n",
                "                'Feature': features,\n",
                "                'Coefficient': model.coef_[0]\n",
                "            }).sort_values(by='Coefficient', ascending=False)\n",
                "            # print(coeffs)\n",
                "            \n",
                "            smoke_coef = coeffs[coeffs['Feature'] == 'smoke']['Coefficient'].values[0]\n",
                "            # print(f\"\\nLogistic Regression Coefficient for 'smoke': {smoke_coef:.4f}\")\n",
                "\n",
                "            # Show Feature Importance Plot\n",
                "            plt.figure(figsize=(10, 6))\n",
                "            sns.barplot(x='Coefficient', y='Feature', data=coeffs)\n",
                "            plt.title('Feature Importance (Logistic Regression)')\n",
                "            plt.tight_layout()\n",
                "            plt.show()\n",
                "        \n",
                "        # Show Confusion Matrix for Random Forest (or best model)\n",
                "        if name == \"Random Forest\":\n",
                "            cm = confusion_matrix(y_test, preds)\n",
                "            plt.figure(figsize=(6, 5))\n",
                "            sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
                "            plt.title(f'Confusion Matrix - {name}')\n",
                "            plt.ylabel('Actual')\n",
                "            plt.xlabel('Predicted')\n",
                "            plt.tight_layout()\n",
                "            plt.show()\n",
                "\n",
                "        if name == \"Decision Tree\":\n",
                "            # Export text representation of the tree rules\n",
                "            tree_rules = export_text(model, feature_names=features)\n",
                "            print(\"\\nDecision Tree Rules (Top 5 levels):\")\n",
                "            print(\"\\n\".join(tree_rules.splitlines()[:20])) # Print first 20 lines\n",
                "\n",
                "    # Generate Model Comparison Plot\n",
                "    perf_df = pd.DataFrame(model_performance).sort_values(by='Accuracy', ascending=False)\n",
                "    \n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.barplot(x='Accuracy', y='Model', data=perf_df, palette='viridis')\n",
                "    plt.title('Model Accuracy Comparison')\n",
                "    plt.xlabel('Accuracy Score')\n",
                "    plt.xlim(0.6, 0.8) # Zoom in for better differentiation on this dataset\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "train_and_evaluate(df)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}